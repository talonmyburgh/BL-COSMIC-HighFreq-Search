# BL-COSMIC-2024-proj

An assortment of compiled work from the Berkeley SETI 2024 REU Intern program with the Breakthrough Listen group. Specifically, work with the COSMIC group which conducts commensal observations using the Karl G. Jansky Very Large Array radio interferometry telescope in New Mexico. Projects included a technosignature search at high frequencies (25-50GHz), investigation of narrowband single-antenna RFI (SARFI) false positives in stamp file data products from the VLA, and an investigation of spurious false positive shits (signals which look technological in origin) being picked up by the COSMIC technosignature pipeline (seticore). Additional work included updating the seticore python viewer package to improve visualization (NMStiegler/seticore) and conducting a literature review of historic technosignaure SETI observation targets. Work was completed across three computer systems: the Breakthrough Listen cluster at UC Berkeley (blpc#), the COSMIC cluster accessed through the NRAO (cosmic-gpu-1) from which stamps files could be accessed, and a laptop running Ubuntu 24.04 LTS. On blpc#, the (cosmic) conda environment running Python 3.8.0 was used for managing data from hits files stored as .pkl files and the (seticore-viewer) running Python 3.9.19 was used to load and view stamp files (dynamic spectra). On cosmic-gpu-1, the (pulsar) conda environment running Python 3.10.14 was used to load metadata from hits files stored in .pkl files and the (stamp_viewer) environment was used to view and manipulate stamp files.

Small disclaimer: the `t` key on my laptop started malfunctioning during this project, so there may be disproportionately more typos where a `t` is missing in this repository.

## Data

The data analyzed for this project include 32M hits collected from the COSMIC system between October, 2023 and February 2024 above 24Ghz for which associated stamps were saved as well as those stamps. For hits which were collected from coherent beams formed on targets from the 30M closest stars in the GAIA catalogue, their GAIA IDs were logged. These are the 2.9M 'coherent' hits searched for technosignatures and there were 13 in total. Hits found in the incoherent beam of the telescope were logged as such and are the 'incoherent' hits. The remaining hits were from coherent beams formed at the center of the incoherent beam because no targets from the 30M closest stars were within the primary FOV of the telescope. These are listed as the 'phase center' targets.

## Structure of the repository

Work in the repository is split into several folders grouping related parts of the project.

### `filters`

The filters folder contains the scripts which ran the technosignature search. The filters removed human-generated technosignatures such as RFI (radio frequency interference) from satellites, noise generated by the electronics, and other spurious signals. The filters were conceived and created iteratively as new understandings about the data were found, so they're not as consolidated and simple as they could be (future filters invalidate previous ones). Each filter runs on the data which passes the previous filter. Filters output the hits which pass them. The results of filters are combined and analyzed in the `after_filters.ipynb` notebook. The intention of and motivation behind each filter are lited in the `filter_descriptions.md`. Stamps of candidates which pass the filters are investigated in `look_a_candidates.ipynb`. `making_filters.ipynb` is a scratch notebook used for testing code which went into the filter scripts. `filter_distances` contains scratch work on filters which use the distance matrix calculated in `frequency_adjacency`.

### `frequency_adjacency`

Contains work to compute the distance (in frequency) between all pairs of hits closer than 1000Hz and analyze the results of that data. The .distances.npz files contain sparse matrices where an enry at indices i and j represents the distance in frequency between hits with indices i and j. The pairs hits whose distances were not computed (because they were more than 1000Hz apart) have 0s as their entries. Because both pairs of hits which are at the same frequency and hits which were not computed have 0 entries, we need a way to tell which distances were actually computed. The .mask.npz files contain sparse matrices wth True for all distances which were computed and False for those which were not computed. 

The `adjacent_in_coherent` directory contains the distance matrix for all coherent data.

The `adjacent_in_each_source` directory contains distance matrices for each source in the coherent data individually (resulting in smaller matrices and less calculation).

The `stamps_of_*` directories contain notebooks (and stamps but those aren't in the repository to save space) for displaying the stamps of hits of interest, such as those from groups with large and small dr (drift rate) or hits found at exactly the same frequency (groups or collision groups).

The `find_adjacent*` scripts are for calculating these distance matrices. The `frequency_adjacent_algorithm*` and `frequency_adjacent_matrices.ipynb` files were scratch work for figuring out the best way to compute them and how much space they'll take up.

The `look_at_all_adjacent_frequencies.ipynb` script is for analyzing the distance matrix computed from all 32M hits.

The `quiver_plots.ipynb` notebook was scratch work for trying to create a plot which visualized the directions that hits are drifting across a frequency over time plot in a clear way.

### `messing_around`

The files in this folder are from my initial exploration of the data and involve initial scratch work from learning the best way to interact with it in pandas. The `col_info.txt` file contains notes on the meanings and units of each column in the dataset. The `messing_around.ipynb` contains most analysis done on the whole 32M hit dataset. The `messing_around_hits.ipynb` file was an exploration of the differences between the hits saved with and without stamps by the seticore system (where hits in the 'hits database' are all those detected and those from the 'stamps database' are those which have an associated stamp). The `messing_around_focused.ipynb` file contains initial exploration of the 2.9M hits from the coherent dataset for technosignatures. Many plots which generally show the data in the dataset used in presentations are from these files.

### `misc`

Contains some other uncategorized work. The `doppler_drift.ipynb` file contains work analyzing the motion required to produce a doppler drift detectable by the COSMIC system. The `find_satellite_positions.ipynb` notebook contains uncompleted work to search the positions observed by the telescope for satellites which might be sources of RFI. The `plots_for_presentation.ipynb` file contains some miscellaneous code used to create plots for the final presentation.

### `pca_exploration`

Contains exploratory work on the potential of the PCA (principal component analysis) to find outliers in the dataset. Was useful for identifying the meaningful columns of data for finding potential technosignatures and reducing the number of features we investigated. The scope of analysis was gradually reduced from the full number of hits detected from a single source to just those from a single pointing of the telescope at a single time.

### `stamps`

Contains work for looking at and analyzing the data from stamps files associated with hits from the dataset. The `look_at_stamps.ipynb` notebook was the initial exploration of data in stamps files. Given the position of the hit in the file couldn't be visualized, updates were written for the seticore python viewer package. These were non-rigorously tested in the `test_seticore_viewer_changes.ipynb` file. 

The `look_at_stamps_which_pass_filer11.ipynb`, `look_at_candidae_stamps`, and `create_candidate_stamp_graphs.py` files are for looking at the stamps files for the hits which pass the filters (where candidates are those that pass filter 12). 

Some work was done to categorize and identify SARFI (single antenna radio frequency interference) which was a large source of false positives in the dataset. To do so, a representative sample of the hits investigated were created (`make_representative_sample_of_stamps.ipynb`) to make a list of hits to investigate the stamps of for SARFI. A large amount of processing was needed to match hits to their associated stamps and compute the amount of signal in each antenna from the stamp file. This work is contained in the `find_antenna_high_power_stamp.ipynb` for initial work on how to find a single high power antenna in a stamp, `figure_out_stamp_file_ordering.ipynb` which explored how to find which stamp in a stamp file corresponds to which hit, `find_SARFI.py` which was the original attempt to invesigate all representative stamps, `investigate_SARFI_script.py` to debug it, `explore_multiprocessing.ipynb` to figure out using multiprocessing to speed up the investigation, `invesigate_file_uris.ipynb` to figure out the use of an index matching hits to stamps created by Dave MacMahon for speeding up the analysis, and `find_SARFI_multi.py` which put all learnings together to generate a list of the powers, SNRs, and physical identifiers of each antenna for each stamp corresponding to a hit from the representative list of hits. The results of these scripts were analyzed in `analyze_*.ipynb`. The `look_at_individual_sarfi.ipynb` script shows plots of the SARFI found in this analysis.

The `dedrift_*` notebooks were for investigating how the seticore search pipeline found hits by following its procedure (dedrifting / dedispersing drifting signals).

`file_info.csv` is an example dataset of hits to explore the stamps of for initial testing and code development. Note that the .pkl files which typically hold datasets of hits can't be opened in environments for which the seticore python viewer works because of python dependency conflicts.

`base_requirements.txt` contains the packages for a conda environment which worked to open and manipulate stamp files.

### work_from_laptop

This folder contains work which was completed on my personal laptop (mostly looking at stamp plots because it was faster to do locally). A script was created (modified from a ChatGPT prompt) to rapidly look through stamp files and mark those which looked notable, `look_at_images.py`. This was modified for the `look_at_images.py` and `look_at_SARFI_images.py` which might actually be a renamed previous version of `look_at_images.py`. This was used to manually label the stamps which contained SARFI to validate algorithms to look for it. The `look_at_promising_candidates.ipynb` notebook was for visually inspecting the 482 candidates which passed filter 12 to find the 12 promising candidates which weren't SARFI. 
